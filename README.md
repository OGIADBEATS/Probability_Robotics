# 概要
このプログラムは, Q学習を用いてロボットが1次元の数直線上を移動し, ゴール地点に到達するための最適な行動を学習するデモンストレーションである.

#機能説明
* ロボットの動作
  * 設定した開始位置から数直線上を移動し, ゴールに到達する機能.
  * 移動は「左移動 (L)」または「右移動 (R)」である.

* Q学習の実装
  * ロボットが行動と報酬を基にQ値を更新.
  * 学習率、割引率、探索率などのパラメータを調整可能.

* 出力
  * 学習後, ゴールまでの最適な行動がコンソールに表示される.

学習後、ゴールまでの最適な行動がコンソールに表示されます。

# 動作の仕組み
* 状態空間 : 数直線上にn個の状態(セル)がある. 左端(状態0)がスタートで、右端（状態𝑛−1）がゴールである.
* 行動空間 : ロボットは「左へ移動(0)」または「右へ移動(1)」の2つの行動が可能である.
* 報酬 :
  1. ゴールに到達 : +1
  2. それ以外: -0.01(小さなペナルティ)
* Q学習 : Qテーブルを学習し, エージェントは最適な行動方針を獲得する.

# 動作環境
* Python 3.7

# 出力結果
* 学習済みのQテーブル
* 報酬の推移を示すグラフ

# 報酬の推移グラフ
* 学習が進むにつれて報酬が安定する様子を確認できる

# 学習の流れ図
+-------+        +-----------+       +-------+
| 状態  | ---->  | 行動選択  | ----> | 更新   |
+-------+        +-----------+       +-------+
   ^                                        |
   |----------------<報酬と次の状態>----------|
